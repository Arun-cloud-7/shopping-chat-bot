ğŸ›ï¸ AI Shopping Chatbot

An AI-powered shopping chatbot that allows users to browse products, add items to a cart, and place an order through a chat-based interface.

The application combines rule-based logic for reliable shopping flows with Google Gemini AI for conversational responses, ensuring both accuracy and natural interaction.

ğŸš€ Live Demo

Frontend (Vercel):
ğŸ‘‰ https://shopping-chat-bot.vercel.app

Backend (FastAPI on Render):
ğŸ‘‰ https://your-backend-name.onrender.com/docs

ğŸ§  Features

ğŸ’¬ Chat-based shopping experience

ğŸ›ï¸ Product listing with images

ğŸ›’ Add products to cart

âœ… Checkout & order confirmation

ğŸ¤– Gemini AI integration for conversational replies

âš ï¸ Graceful fallback when AI quota is exceeded

ğŸŒ Fully deployed and accessible online

ğŸ› ï¸ Tech Stack
Frontend

HTML

CSS (Modern dark UI)

Vanilla JavaScript

Deployed on Vercel

Backend

Python

FastAPI

Google Gemini API

Deployed on Render

Data

JSON-based product dataset (no database)

ğŸ—ï¸ Project Architecture
ai-shopping-chatbot/
â”‚
â”œâ”€â”€ frontend/        # Static UI (Vercel)
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ script.js
â”‚
â”œâ”€â”€ backend/         # FastAPI server (Render)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ chatbot.py
â”‚   â”œâ”€â”€ gemini_client.py
â”‚   â”œâ”€â”€ products.json
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ README.md

âš™ï¸ How It Works

Rule-based logic handles:

Listing products

Adding to cart

Checkout and order confirmation

Gemini AI is used only for:

Natural conversation

Greetings and open-ended queries

This approach avoids AI hallucinations and keeps the core shopping flow reliable.

â–¶ï¸ Run Locally
1ï¸âƒ£ Backend Setup
cd backend
pip install -r requirements.txt
uvicorn main:app --reload


Create a .env file inside backend/:

GEMINI_API_KEY=your_gemini_api_key_here


Backend runs at:

http://127.0.0.1:8000

2ï¸âƒ£ Frontend Setup

Open frontend/index.html directly in your browser
(or use Live Server in VS Code).

Make sure script.js points to the backend URL:

fetch("http://127.0.0.1:8000/chat")

ğŸŒ Deployment

Frontend: Deployed on Vercel as a static site

Backend: Deployed on Render as a FastAPI service

Environment variables: Managed securely via platform settings

ğŸ“Œ Example Chat Flow
User: Show products
Bot: (Displays product cards with images)

User: Add Backpack
Bot: Backpack added to cart.

User: Checkout
Bot: Order confirmed. Total: â‚¹2499

ğŸ§ª AI Rate Limit Handling

The app gracefully handles Gemini API rate limits:

Core shopping actions continue to work

AI responses fall back to predefined helpful messages

No crashes or broken UI

ğŸ¯ Evaluation Focus

This project demonstrates:

Practical AI integration

Clean frontendâ€“backend separation

Defensive programming & error handling

Ability to deploy a complete working system
